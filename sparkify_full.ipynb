{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "# Starter code\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, lit, udf, isnan, count, when, desc, sort_array, asc, avg, lag, floor\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import IntegerType, DateType\nfrom pyspark.sql.functions import sum as Fsum\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import MinMaxScaler #used because won't distort binary vars\nfrom pyspark.sql.types import DoubleType\nimport datetime\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.mllib.evaluation import MulticlassMetrics\nimport numpy as np\n\n# Create spark session\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Sparkify\") \\\n    .getOrCreate()\n\n# Read in full sparkify dataset\nevent_data = \"s3n://dsnd-sparkify/sparkify_event_data.json\"\ndata = spark.read.json(event_data)\ndata.head()", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "da2b614d6a4e49dc9740c703aaceeb62"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "da2b614d6a4e49dc9740c703aaceeb62"}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\nStarting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8</td><td>application_1548099680497_0009</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-32-118.us-east-2.compute.internal:20888/proxy/application_1548099680497_0009/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-47-66.us-east-2.compute.internal:8042/node/containerlogs/container_1548099680497_0009_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8</td><td>application_1548099680497_0009</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-32-118.us-east-2.compute.internal:20888/proxy/application_1548099680497_0009/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-47-66.us-east-2.compute.internal:8042/node/containerlogs/container_1548099680497_0009_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\nSparkSession available as 'spark'.\nRow(artist=u'Popol Vuh', auth=u'Logged In', firstName=u'Shlok', gender=u'M', itemInSession=278, lastName=u'Johnson', length=524.32934, level=u'paid', location=u'Dallas-Fort Worth-Arlington, TX', method=u'PUT', page=u'NextSong', registration=1533734541000, sessionId=22683, song=u'Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent=u'\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId=u'1749042')Row(artist=u'Popol Vuh', auth=u'Logged In', firstName=u'Shlok', gender=u'M', itemInSession=278, lastName=u'Johnson', length=524.32934, level=u'paid', location=u'Dallas-Fort Worth-Arlington, TX', method=u'PUT', page=u'NextSong', registration=1533734541000, sessionId=22683, song=u'Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent=u'\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId=u'1749042')", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#define necessary functions\ndef feature_engineering(df):\n    '''\n    Create necessary features to use machine learning algorithms.\n    First loads data set from file\n    \n    Resulting DF Strucutre:\n    \n    root\n     |-- userId: string\n     |-- downgraded: long\n     |-- cancelled: long\n     |-- visited_cancel: long\n     |-- visited_downgrade: long\n     |-- dailyHelpVisits: double\n     |-- dailyErrors: double\n     |-- free: integer\n     |-- paid: integer\n     |-- avgThumbsUp: double\n     |-- avgThumbsDOwn: double\n     |-- numFriends: long\n     |-- avgSongsTillHome: double\n     |-- avgTimeSkipped: double\n     |-- skipRate: double\n    \n    Inputs\n        filepath (str) - path to json dataset on file\n        \n    Outputs\n        data - engineered dataset\n    '''\n    df.persist() #maintain data in memory to speed up feature engineering process\n    #dataframe of user ids to merge onto\n    users = df.where((df.userId != \"\") | (df.sessionId != \"\"))\\\n        .select('userId').dropDuplicates()\n    df = df.where((df.userId != \"\") | (df.sessionId != \"\")) #clean dataframe\n    \n    #define custom functions\n    churn = udf(lambda x: int(x==\"Cancellation Confirmation\"), IntegerType())\n    downgrade_churn = udf(lambda x: int(x==\"Submit Downgrade\"), IntegerType())\n    visited_downgrade = udf(lambda x: int(x=='Downgrade'), IntegerType())\n    visited_cancel = udf(lambda x: int(x=='Cancel'), IntegerType())\n    song = udf(lambda x: int(x=='NextSong'), IntegerType())\n    days = lambda i: i * 86400 \n    get_day = udf(lambda x: datetime.datetime.fromtimestamp(x/1000), DateType())\n    skipped = udf(lambda x: int(x!=0), IntegerType())\n    free = udf(lambda x: int(x=='free'), IntegerType())\n    paid = udf(lambda x: int(x=='paid'), IntegerType())\n    home_visit=udf(lambda x : int(x=='Home'), IntegerType())\n    \n    #define windows\n    windowval = Window.partitionBy(\"userId\").orderBy(desc(\"ts\")).rangeBetween(Window.unboundedPreceding, 0)\n    session = Window.partitionBy(\"userId\", \"sessionId\").orderBy(desc(\"ts\"))\n    daywindow = Window.partitionBy('userId', 'date').orderBy(desc('ts'))\\\n        .rangeBetween(Window.unboundedPreceding, 0)\n\n    #count average daily occurences of thumbs up per user\n    avgThumbsUp = df.filter(df.page=='Thumbs Up')\\\n        .select('userId', 'page', 'ts')\\\n        .withColumn('date', get_day(col('ts')))\\\n        .groupBy('userId', 'date').agg({'page':'count'}).groupBy('userId')\\\n        .mean().withColumnRenamed('avg(count(page))', 'avgThumbsUp')\n\n    #count average daily occurences of thumbs up per user\n    avgThumbsDown = df.filter(df.page=='Thumbs Down')\\\n        .select('userId', 'page', 'ts')\\\n        .withColumn('date', get_day(col('ts')))\\\n        .groupBy('userId', 'date').agg({'page':'count'})\\\n        .groupBy('userId').mean()\\\n        .withColumnRenamed('avg(count(page))', 'avgThumbsDown')\n\n    #count the number of friends each user has\n    numFriends = df.filter(df.page=='Add Friend')\\\n        .select('userId', 'page')\\\n        .groupBy('userId').count().withColumnRenamed('count', 'numFriends')\n    \n    '''\n    Calculate average time of song skipped\n    process for calculating skipping variables\n\n    1. dont include thumbs up and down pages because that usually occurs \n        while playing and does not change song\n    2. create variable for if action is song\n    3. check if next action is song - this will check to see if someone is \n        skipping song or just leaving page\n    4. get the difference in timestamp for next action song playing\n    5. subtract the difference in timestamp from song length to see \n        how much of song was skipped\n    6. get descriptive stats\n    '''\n    skipping = df.select('userId', 'page', 'ts', 'length', 'sessionId', 'itemInSession')\\\n        .where((df.page != 'Thumbs Up') & (df.page != 'Thumbs Down'))\\\n        .withColumn('song', song('page')).orderBy('userId', 'sessionId', 'itemInSession')\\\n        .withColumn('nextActSong', lag(col('song')).over(session))\\\n        .withColumn('tsDiff', (lag('ts').over(session)-col('ts'))/1000)\\\n        .withColumn('timeSkipped', (floor('length')-col('tsDiff')))\\\n        .withColumn('roundedLength', floor('length'))\\\n        .where((col('song')==1) & ((col('nextActSong')!=0)&(col('timeSkipped')>=0)))\\\n        .withColumn('skipped', skipped('timeSkipped'))\\\n        .select('userId', 'timeSkipped', 'skipped', 'length', 'ts', 'tsDiff')\\\n        .groupBy('userId').agg({'skipped':'avg', 'timeSkipped':'avg'})\\\n        .withColumnRenamed('avg(skipped)', 'skipRate')\\\n        .withColumnRenamed('avg(timeSkipped)', 'avgTimeSkipped')\n    \n    #avg daily visits to help site\n    dailyHelpVisit = df.filter(df.page=='Help')\\\n        .select('userId', 'page', 'ts', 'length')\\\n        .withColumn('date', get_day(col('ts')))\\\n        .groupBy('userId', 'date').agg({'page':'count'})\\\n        .groupBy('userId').mean()\\\n         .withColumnRenamed('avg(count(page))', 'dailyHelpVisits')\n\n    #count average daily errors occured\n    dailyErrors = df.filter(df.page=='Error')\\\n        .select('userId', 'page', 'ts', 'length')\\\n        .withColumn('date', get_day(col('ts')))\\\n        .groupBy('userId', 'date').agg({'page':'count'})\\\n        .groupBy('userId').mean()\\\n        .withColumnRenamed('avg(count(page))', 'dailyErrors')\n    \n    #whether a user has downgraded\n    churn = df.withColumn(\"downgraded\", downgrade_churn(\"page\"))\\\n        .withColumn(\"cancelled\", churn(\"page\"))\\\n        .withColumn('visited_cancel', visited_cancel('page'))\\\n        .withColumn('visited_downgrade', visited_downgrade('page'))\\\n        .select(['userId', 'downgraded', 'cancelled', 'visited_cancel', 'visited_downgrade'])\\\n        .groupBy('userId').sum()\\\n        .withColumnRenamed('sum(downgraded)', 'downgraded')\\\n        .withColumnRenamed('sum(cancelled)', 'cancelled')\\\n        .withColumnRenamed('sum(visited_cancel)', 'visited_cancel')\\\n        .withColumnRenamed('sum(visited_downgrade)', 'visited_downgrade')\n\n    #assign the user a current level (free, paid) by dropping all duplicate values, and keeping most recent vals\n    user_level = df.select('userId', 'level','ts')\\\n        .where((df.level=='free')|(df.level=='paid'))\\\n        .orderBy(desc('ts')).drop('ts').dropDuplicates()\\\n        .withColumn('free', free('level'))\\\n        .withColumn('paid', paid('level')).drop('level')\n\n    #mark each song between home visit with a 1\n    cusum = df.filter((df.page == 'NextSong') | (df.page == 'Home')) \\\n        .select('userID', 'page', 'ts') \\\n        .withColumn('homevisit', home_visit(col('page'))) \\\n        .withColumn('songPeriod', Fsum('homevisit').over(windowval))\\\n    \n    #calculate average number of songs played between each home visit\n    avgSongsTillHome = cusum.filter((cusum.page=='NextSong'))\\\n        .groupBy('userId', 'songPeriod')\\\n        .agg({'songPeriod':'count'}).drop('songPeriod')\\\n        .groupby('userId').mean()\\\n        .withColumnRenamed('avg(count(songPeriod))', 'avgSongsTillHome')\n    \n    #combine user id on \n    df = users.join(churn, on='userId')\\\n        .join(dailyHelpVisit, on='userId')\\\n        .join(dailyErrors, on='userId')\\\n        .join(user_level, on='userId')\\\n        .join(avgThumbsUp, on='userId')\\\n        .join(avgThumbsDown, on='userId')\\\n        .join(numFriends, on='userId')\\\n        .join(avgSongsTillHome, on='userId')\\\n        .join(skipping, on='userId')\n    return df\n\ndef feature_scaling(df):\n    '''\n    Function takes care of scaling inputs into the model to between [0,1]\n    Otherwise if the values weren't scaled then the feature with highest values would dominate the training.\n    \n    Input\n        df (Spark DataFrame)\n        \n    Output\n        scaled_df (Spark DataFrame)\n    '''\n    df.persist() #keep df in memory to speed up computation\n    \n    feature_cols = df.drop('userId', 'cancelled').columns\n    assembler = VectorAssembler(inputCols=feature_cols,\\\n                                outputCol='feature_vec')\n    \n    #pyspark.ml expects target column to be names: 'labelCol', w/ type: Double\n    df = df.withColumn(\"label\", df[\"cancelled\"].cast(DoubleType()))\n    \n    #pyspark default name for features vector column: 'featuresCol'\n    minmaxscaler = MinMaxScaler(inputCol=\"feature_vec\", outputCol=\"features\")\n    \n    df = assembler.transform(df)\n    minmaxscaler_model = minmaxscaler.fit(df)\n    scaled_df = minmaxscaler_model.transform(df)\n    return scaled_df\n\ndef custom_evaluation(pred, model_name):\n    '''\n    Perform custom evaluation of predictions\n    \n    1.inspect with PySpark.ML evaluator (will use for pipeline)\n    2. use RDD-API; PySpark.MLLib to get metrics based on predictions \n    3. display confusion matrix\n    \n    Inspiration from: https://chih-ling-hsu.github.io/2018/09/17/spark-mllib\n    https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html\n    https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n    \n    Inputs\n        preds(PySpark.ml.DataFrame) - predictions from model\n    '''\n    #want to evaluate binary class, auc_pr is best for imbalanced classes\n    tn_sum = pred.filter((pred.label == 0)&(pred.prediction==0)).count() #true negative\n    fn_sum = pred.filter((pred.label == 1)&(pred.prediction==0)).count() #false negative\n    fp_sum = pred.filter((pred.label == 0)&(pred.prediction==1)).count() #false positive\n    tp_sum = pred.filter((pred.label == 1)&(pred.prediction==1)).count() #true positive\n\n    print(\"{} \\n | tn:{}| fn:{}| fp:{}| tp:{}\".format(model_name, tn_sum, fn_sum, fp_sum, tp_sum))", "execution_count": 18, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3bacbb9dde884abc9fa71b74a3f7bc62"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3bacbb9dde884abc9fa71b74a3f7bc62"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#prepare data for ML\ndf = feature_engineering(data)", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e76aaa97574f44a9a8ebc2c7be87e9fa"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e76aaa97574f44a9a8ebc2c7be87e9fa"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#scale features for ML algo\ndf_scaled = feature_scaling(df)", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c9acef1884ad4764bb5b8f86af26bc26"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c9acef1884ad4764bb5b8f86af26bc26"}}, "metadata": {}}, {"output_type": "stream", "text": "----------------------------------------\nException happened during processing of request from ('127.0.0.1', 42418)\n----------------------------------------\nTraceback (most recent call last):\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 290, in _handle_request_noblock\n    self.process_request(request, client_address)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 318, in process_request\n    self.finish_request(request, client_address)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 331, in finish_request\n    self.RequestHandlerClass(request, client_address, self)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 652, in __init__\n    self.handle()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 266, in handle\n    poll(authenticate_and_accum_updates)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 241, in poll\n    if func():\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 254, in authenticate_and_accum_updates\n    received_token = self.rfile.read(len(auth_token))\nTypeError: object of type 'NoneType' has no len()----------------------------------------\nException happened during processing of request from ('127.0.0.1', 42418)\n----------------------------------------\nTraceback (most recent call last):\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 290, in _handle_request_noblock\n    self.process_request(request, client_address)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 318, in process_request\n    self.finish_request(request, client_address)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 331, in finish_request\n    self.RequestHandlerClass(request, client_address, self)\n  File \"/usr/lib64/python2.7/SocketServer.py\", line 652, in __init__\n    self.handle()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 266, in handle\n    poll(authenticate_and_accum_updates)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 241, in poll\n    if func():\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 254, in authenticate_and_accum_updates\n    received_token = self.rfile.read(len(auth_token))\nTypeError: object of type 'NoneType' has no len()", "name": "stdout"}]}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "df_scaled.collect()[0]", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "09cddd9d632f47b3bd390e64026f0737"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "09cddd9d632f47b3bd390e64026f0737"}}, "metadata": {}}, {"output_type": "stream", "text": "Row(userId=u'1000280', downgraded=1, cancelled=1, visited_cancel=1, visited_downgrade=3, dailyHelpVisits=1.6, dailyErrors=1.0, free=1, paid=0, avgThumbsUp=3.533333333333333, avgThumbsDown=2.0625, numFriends=14, avgSongsTillHome=24.333333333333332, avgTimeSkipped=0.0, skipRate=0.0, label=1.0, feature_vec=DenseVector([1.0, 1.0, 3.0, 1.6, 1.0, 1.0, 0.0, 3.5333, 2.0625, 14.0, 24.3333, 0.0, 0.0]), features=DenseVector([0.1429, 1.0, 0.0226, 0.12, 0.0, 1.0, 0.0, 0.1378, 0.1678, 0.0588, 0.2301, 0.0, 0.0]))Row(userId=u'1000280', downgraded=1, cancelled=1, visited_cancel=1, visited_downgrade=3, dailyHelpVisits=1.6, dailyErrors=1.0, free=1, paid=0, avgThumbsUp=3.533333333333333, avgThumbsDown=2.0625, numFriends=14, avgSongsTillHome=24.333333333333332, avgTimeSkipped=0.0, skipRate=0.0, label=1.0, feature_vec=DenseVector([1.0, 1.0, 3.0, 1.6, 1.0, 1.0, 0.0, 3.5333, 2.0625, 14.0, 24.3333, 0.0, 0.0]), features=DenseVector([0.1429, 1.0, 0.0226, 0.12, 0.0, 1.0, 0.0, 0.1378, 0.1678, 0.0588, 0.2301, 0.0, 0.0]))", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#split data for training\ntrain, rest = df_scaled.randomSplit([0.85, 0.15], seed=42)\nvalidation, test = rest.randomSplit([0.5,0.5], seed=42)", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d164c9b45709484cbc8eedee90d63dc3"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d164c9b45709484cbc8eedee90d63dc3"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "train.persist() #reduce computational time", "execution_count": 19, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "573eef9d7b944482a9f39985190d69ed"}}, "metadata": {}}, {"output_type": "stream", "text": "DataFrame[userId: string, downgraded: bigint, cancelled: bigint, visited_cancel: bigint, visited_downgrade: bigint, dailyHelpVisits: double, dailyErrors: double, free: int, paid: int, avgThumbsUp: double, avgThumbsDown: double, numFriends: bigint, avgSongsTillHome: double, avgTimeSkipped: double, skipRate: double, label: double, feature_vec: vector, features: vector]", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "573eef9d7b944482a9f39985190d69ed"}}, "metadata": {}}, {"output_type": "stream", "text": "DataFrame[userId: string, downgraded: bigint, cancelled: bigint, visited_cancel: bigint, visited_downgrade: bigint, dailyHelpVisits: double, dailyErrors: double, free: int, paid: int, avgThumbsUp: double, avgThumbsDown: double, numFriends: bigint, avgSongsTillHome: double, avgTimeSkipped: double, skipRate: double, label: double, feature_vec: vector, features: vector]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#random forest classifier model\nfrom pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(numTrees=10)\nrf_model = rf.fit(train)\nrf_preds = rf_model.transform(validation)\ncustom_evaluation(rf_preds, 'Random Forest')", "execution_count": 20, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "cd5122aea9fa4fa9b1038464d3ad6e89"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "cd5122aea9fa4fa9b1038464d3ad6e89"}}, "metadata": {}}, {"output_type": "stream", "text": "Random Forest \n | tn:1043| fn:0| fp:0| tp:279Random Forest \n | tn:1043| fn:0| fp:0| tp:279", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#gradient boosted trees (ie ada boost)\nfrom pyspark.ml.classification import GBTClassifier\ngbtrees = GBTClassifier(maxIter=10)\ngbtree_model = gbtrees.fit(train)\ngbtree_preds = gbtree_model.transform(validation)\ncustom_evaluation(gbtree_preds, 'Gradient Boosted Trees')", "execution_count": 21, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e6482c98a63e4c12be6a0d1f6ed689aa"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e6482c98a63e4c12be6a0d1f6ed689aa"}}, "metadata": {}}, {"output_type": "stream", "text": "Exception in thread cell_monitor-21:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/awseditorssparkmonitoringwidget-1.0-py3.6.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\nKeyError: 5147\n\nException in thread cell_monitor-21:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/awseditorssparkmonitoringwidget-1.0-py3.6.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\nKeyError: 5147\n\n", "name": "stderr"}, {"output_type": "stream", "text": "Gradient Boosted Trees \n | tn:1043| fn:0| fp:0| tp:279Gradient Boosted Trees \n | tn:1043| fn:0| fp:0| tp:279", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#SVM: https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-support-vector-machine\n\nfrom pyspark.ml.classification import LinearSVC\nsvm = LinearSVC(maxIter=10, regParam=0.1)\nsvm_model=svm.fit(train)\nsvm_preds=svm_model.transform(validation)\ncustom_evaluation(svm_preds, 'Support Vector Machine')", "execution_count": 22, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6bceca4ee54d485184b146ee6fb0a876"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6bceca4ee54d485184b146ee6fb0a876"}}, "metadata": {}}, {"output_type": "stream", "text": "Support Vector Machine \n | tn:1043| fn:0| fp:0| tp:279Support Vector Machine \n | tn:1043| fn:0| fp:0| tp:279", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#logistic regression model\nfrom pyspark.ml.classification import LogisticRegression\nlogReg = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\nlrModel = logReg.fit(train)\nlr_preds = lrModel.transform(validation)\n\ncustom_evaluation(lr_preds, 'Logistic Regression')", "execution_count": 23, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d2c668ea319a4a7487eafa01555bb472"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d2c668ea319a4a7487eafa01555bb472"}}, "metadata": {}}, {"output_type": "stream", "text": "Logistic Regression \n | tn:1043| fn:279| fp:0| tp:0Logistic Regression \n | tn:1043| fn:279| fp:0| tp:0", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Compare Results to make sure they are accurate"}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "#visual check for predictions\nfor x in [svm_preds, lr_preds, gbtree_preds, rf_preds]:\n    x.select('features', 'rawPrediction', 'prediction', 'label').show(20)", "execution_count": 24, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3fe93d0d0dc246a49ce2873ce7e278bc"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3fe93d0d0dc246a49ce2873ce7e278bc"}}, "metadata": {}}, {"output_type": "stream", "text": "+--------------------+--------------------+----------+-----+\n|            features|       rawPrediction|prediction|label|\n+--------------------+--------------------+----------+-----+\n|[0.0,0.0,0.0,0.06...|[1.29454586908108...|       0.0|  0.0|\n|[0.0,0.0,0.0,0.1,...|[0.91650298266328...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.26981895598087...|       0.0|  0.0|\n|[0.0,0.0,0.022556...|[1.06079024054081...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.30126183663906...|       0.0|  0.0|\n|[0.14285714285714...|[1.66035588375266...|       0.0|  0.0|\n|[0.14285714285714...|[1.00878880062720...|       0.0|  0.0|\n|[0.0,0.0,0.037593...|[1.24246986138686...|       0.0|  0.0|\n|[0.14285714285714...|[1.52749153383729...|       0.0|  0.0|\n|[0.14285714285714...|[1.51957700662642...|       0.0|  0.0|\n|[0.14285714285714...|[1.31041568085742...|       0.0|  0.0|\n|[0.14285714285714...|[1.76545507949694...|       0.0|  0.0|\n|[0.0,0.0,0.052631...|[1.05925139204592...|       0.0|  0.0|\n|[0.28571428571428...|[1.49112193157191...|       0.0|  0.0|\n|[0.0,0.0,0.015037...|[0.88029793066967...|       0.0|  0.0|\n|[0.0,0.0,0.060150...|[1.21034612106780...|       0.0|  0.0|\n|[0.0,1.0,0.127819...|[-0.9208442402989...|       1.0|  1.0|\n|[0.28571428571428...|[-0.9351943662069...|       1.0|  1.0|\n|[0.14285714285714...|[-1.0389279243585...|       1.0|  1.0|\n|[0.0,0.0,0.165413...|[1.35456249742059...|       0.0|  0.0|\n+--------------------+--------------------+----------+-----+\nonly showing top 20 rows\n\n+--------------------+--------------------+----------+-----+\n|            features|       rawPrediction|prediction|label|\n+--------------------+--------------------+----------+-----+\n|[0.0,0.0,0.0,0.06...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.0,0.1,...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.022556...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.037593...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.052631...|[1.73692831608563...|       0.0|  0.0|\n|[0.28571428571428...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.015037...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.060150...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,1.0,0.127819...|[0.10661600591133...|       0.0|  1.0|\n|[0.28571428571428...|[0.10661600591133...|       0.0|  1.0|\n|[0.14285714285714...|[0.10661600591133...|       0.0|  1.0|\n|[0.0,0.0,0.165413...|[1.73692831608563...|       0.0|  0.0|\n+--------------------+--------------------+----------+-----+\nonly showing top 20 rows\n\n+--------------------+--------------------+----------+-----+\n|            features|       rawPrediction|prediction|label|\n+--------------------+--------------------+----------+-----+\n|[0.0,0.0,0.0,0.06...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.0,0.1,...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.022556...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.037593...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.052631...|[1.32590267922033...|       0.0|  0.0|\n|[0.28571428571428...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.015037...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.060150...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,1.0,0.127819...|[-1.3259026792203...|       1.0|  1.0|\n|[0.28571428571428...|[-1.3259026792203...|       1.0|  1.0|\n|[0.14285714285714...|[-1.3259026792203...|       1.0|  1.0|\n|[0.0,0.0,0.165413...|[1.32590267922033...|       0.0|  0.0|\n+--------------------+--------------------+----------+-----+\nonly showing top 20 rows\n\n+--------------------+--------------------+----------+-----+\n|            features|       rawPrediction|prediction|label|\n+--------------------+--------------------+----------+-----+\n|[0.0,0.0,0.0,0.06...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.0,0.1,...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.120300...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.022556...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[9.28000000000000...|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.037593...|          [10.0,0.0]|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.14285714285714...|[9.74352527030425...|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.052631...|          [10.0,0.0]|       0.0|  0.0|\n|[0.28571428571428...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.015037...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.060150...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,1.0,0.127819...|          [0.0,10.0]|       1.0|  1.0|\n|[0.28571428571428...|          [0.0,10.0]|       1.0|  1.0|\n|[0.14285714285714...|          [0.0,10.0]|       1.0|  1.0|\n|[0.0,0.0,0.165413...|          [10.0,0.0]|       0.0|  0.0|\n+--------------------+--------------------+----------+-----+\nonly showing top 20 rows+--------------------+--------------------+----------+-----+\n|            features|       rawPrediction|prediction|label|\n+--------------------+--------------------+----------+-----+\n|[0.0,0.0,0.0,0.06...|[1.29454586908108...|       0.0|  0.0|\n|[0.0,0.0,0.0,0.1,...|[0.91650298266328...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.26981895598087...|       0.0|  0.0|\n|[0.0,0.0,0.022556...|[1.06079024054081...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.30126183663906...|       0.0|  0.0|\n|[0.14285714285714...|[1.66035588375266...|       0.0|  0.0|\n|[0.14285714285714...|[1.00878880062720...|       0.0|  0.0|\n|[0.0,0.0,0.037593...|[1.24246986138686...|       0.0|  0.0|\n|[0.14285714285714...|[1.52749153383729...|       0.0|  0.0|\n|[0.14285714285714...|[1.51957700662642...|       0.0|  0.0|\n|[0.14285714285714...|[1.31041568085742...|       0.0|  0.0|\n|[0.14285714285714...|[1.76545507949694...|       0.0|  0.0|\n|[0.0,0.0,0.052631...|[1.05925139204592...|       0.0|  0.0|\n|[0.28571428571428...|[1.49112193157191...|       0.0|  0.0|\n|[0.0,0.0,0.015037...|[0.88029793066967...|       0.0|  0.0|\n|[0.0,0.0,0.060150...|[1.21034612106780...|       0.0|  0.0|\n|[0.0,1.0,0.127819...|[-0.9208442402989...|       1.0|  1.0|\n|[0.28571428571428...|[-0.9351943662069...|       1.0|  1.0|\n|[0.14285714285714...|[-1.0389279243585...|       1.0|  1.0|\n|[0.0,0.0,0.165413...|[1.35456249742059...|       0.0|  0.0|\n+--------------------+--------------------+----------+-----+\nonly showing top 20 rows\n\n+--------------------+--------------------+----------+-----+\n|            features|       rawPrediction|prediction|label|\n+--------------------+--------------------+----------+-----+\n|[0.0,0.0,0.0,0.06...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.0,0.1,...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.022556...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.037593...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.14285714285714...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.052631...|[1.73692831608563...|       0.0|  0.0|\n|[0.28571428571428...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.015037...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,0.0,0.060150...|[1.73692831608563...|       0.0|  0.0|\n|[0.0,1.0,0.127819...|[0.10661600591133...|       0.0|  1.0|\n|[0.28571428571428...|[0.10661600591133...|       0.0|  1.0|\n|[0.14285714285714...|[0.10661600591133...|       0.0|  1.0|\n|[0.0,0.0,0.165413...|[1.73692831608563...|       0.0|  0.0|\n+--------------------+--------------------+----------+-----+\nonly showing top 20 rows\n\n+--------------------+--------------------+----------+-----+\n|            features|       rawPrediction|prediction|label|\n+--------------------+--------------------+----------+-----+\n|[0.0,0.0,0.0,0.06...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.0,0.1,...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.022556...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.037593...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.14285714285714...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.052631...|[1.32590267922033...|       0.0|  0.0|\n|[0.28571428571428...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.015037...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,0.0,0.060150...|[1.32590267922033...|       0.0|  0.0|\n|[0.0,1.0,0.127819...|[-1.3259026792203...|       1.0|  1.0|\n|[0.28571428571428...|[-1.3259026792203...|       1.0|  1.0|\n|[0.14285714285714...|[-1.3259026792203...|       1.0|  1.0|\n|[0.0,0.0,0.165413...|[1.32590267922033...|       0.0|  0.0|\n+--------------------+--------------------+----------+-----+\nonly showing top 20 rows\n\n+--------------------+--------------------+----------+-----+\n|            features|       rawPrediction|prediction|label|\n+--------------------+--------------------+----------+-----+\n|[0.0,0.0,0.0,0.06...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.0,0.1,...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.120300...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.022556...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.120300...|[9.28000000000000...|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.037593...|          [10.0,0.0]|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.14285714285714...|[9.74352527030425...|       0.0|  0.0|\n|[0.14285714285714...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.052631...|          [10.0,0.0]|       0.0|  0.0|\n|[0.28571428571428...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.015037...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,0.0,0.060150...|          [10.0,0.0]|       0.0|  0.0|\n|[0.0,1.0,0.127819...|          [0.0,10.0]|       1.0|  1.0|\n|[0.28571428571428...|          [0.0,10.0]|       1.0|  1.0|\n|[0.14285714285714...|          [0.0,10.0]|       1.0|  1.0|\n|[0.0,0.0,0.165413...|          [10.0,0.0]|       0.0|  0.0|\n+--------------------+--------------------+----------+-----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#PCA\n#https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.feature.PCA\nfrom pyspark.ml.feature import PCA\n\n\n#first create PCA with all the feeatures kept- 13 features\npca_full = PCA(k=13, inputCol=\"features\", outputCol=\"pcaFeatures\")\npca_model_full = pca_full.fit(df_scaled)\npca_model_full.explainedVariance", "execution_count": 25, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "98c03e24d7d64fa0812c04a08cb84214"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "98c03e24d7d64fa0812c04a08cb84214"}}, "metadata": {}}, {"output_type": "stream", "text": "DenseVector([0.6684, 0.2304, 0.0372, 0.018, 0.0149, 0.01, 0.008, 0.0075, 0.0032, 0.0019, 0.0006, 0.0, 0.0])DenseVector([0.6684, 0.2304, 0.0372, 0.018, 0.0149, 0.01, 0.008, 0.0075, 0.0032, 0.0019, 0.0006, 0.0, 0.0])", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The explained variance vector shows that 97.69% of the variance in the dataset can be explained by the first 6 features. We really do not need more features than that from PCA."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "pca_final = PCA(k=6, inputCol=\"features\", outputCol=\"pcaFeatures\")\npca_model = pca_final.fit(df_scaled)\ndf_scaled_pca = pca_model.transform(df_scaled)", "execution_count": 26, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "49763cc721074c6fb47b9ec0d268cf37"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "49763cc721074c6fb47b9ec0d268cf37"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#split data for training\ntrain_pca, rest_pca = df_scaled_pca.randomSplit([0.85, 0.15], seed=42)\nvalidation_pca, test_pca = rest_pca.randomSplit([0.5,0.5], seed=42)", "execution_count": 27, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d416d93619be4569924b341a7313de73"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d416d93619be4569924b341a7313de73"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "svm_pca = LinearSVC(featuresCol='pcaFeatures', maxIter=10, regParam=0.1)", "execution_count": 28, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "16147556067c479eb61ac2e2d69a97b3"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "16147556067c479eb61ac2e2d69a97b3"}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "svm_pca_model=svm_pca.fit(train_pca)\nsvm_preds_pca=svm_pca_model.transform(validation_pca)\ncustom_evaluation(svm_preds_pca, 'Support Vector Machine')", "execution_count": 29, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "682dc5cb40a14363b54642150bfedb90"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "682dc5cb40a14363b54642150bfedb90"}}, "metadata": {}}, {"output_type": "stream", "text": "Exception in thread cell_monitor-22:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/awseditorssparkmonitoringwidget-1.0-py3.6.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\nKeyError: 6607\n\nException in thread cell_monitor-22:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/awseditorssparkmonitoringwidget-1.0-py3.6.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\nKeyError: 6607\n\nException in thread cell_monitor-29:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/awseditorssparkmonitoringwidget-1.0-py3.6.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\nKeyError: 7551\n\n", "name": "stderr"}, {"output_type": "stream", "text": "Support Vector Machine \n | tn:1043| fn:0| fp:0| tp:279", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}